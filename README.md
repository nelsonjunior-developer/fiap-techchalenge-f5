



üìÅ Project Structure

The repository is organized to clearly separate data handling, model training, API serving, monitoring, and tests, ensuring maintainability, reproducibility, and ease of deployment.

```
project-root/
‚îÇ
‚îú‚îÄ‚îÄ app/                         # API layer (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # FastAPI application entrypoint
‚îÇ   ‚îú‚îÄ‚îÄ routes.py                # API routes (/predict, /health, /version)
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py               # Pydantic request/response schemas
‚îÇ   ‚îî‚îÄ‚îÄ model/
‚îÇ       ‚îú‚îÄ‚îÄ model.joblib         # Trained ML pipeline (serialized)
‚îÇ       ‚îú‚îÄ‚îÄ metadata.json        # Model metadata (metrics, threshold, version)
‚îÇ       ‚îî‚îÄ‚îÄ reference_data.csv   # Reference dataset for drift monitoring
‚îÇ
‚îú‚îÄ‚îÄ src/                         # Core ML pipeline
‚îÇ   ‚îú‚îÄ‚îÄ data.py                  # Load XLSX, standardize columns, create t‚Üít+1 pairs
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py         # Data cleaning, encoding, scaling
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py   # Feature creation and selection
‚îÇ   ‚îú‚îÄ‚îÄ train.py                 # Model training and internal validation
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py              # Metrics, confusion matrix, threshold selection
‚îÇ   ‚îú‚îÄ‚îÄ drift.py                 # Drift detection with Evidently
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                 # Shared utilities (logging, configs, helpers)
‚îÇ
‚îú‚îÄ‚îÄ dashboards/
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py         # Streamlit dashboard to visualize drift reports
‚îÇ
‚îú‚îÄ‚îÄ tests/                       # Unit and integration tests (pytest)
‚îÇ   ‚îú‚îÄ‚îÄ test_data.py             # Tests for data loading and temporal pairing
‚îÇ   ‚îú‚îÄ‚îÄ test_preprocessing.py    # Tests for preprocessing steps
‚îÇ   ‚îú‚îÄ‚îÄ test_feature_engineering.py
‚îÇ   ‚îú‚îÄ‚îÄ test_train_smoke.py      # Smoke test for training pipeline
‚îÇ   ‚îî‚îÄ‚îÄ test_api_predict.py      # API endpoint tests (/predict)
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                   # (Optional) Exploratory analysis and experiments
‚îÇ
‚îú‚îÄ‚îÄ Dockerfile                   # Docker image definition for API deployment
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ README.md                    # Project documentation
‚îî‚îÄ‚îÄ .gitignore                   # Git ignore rules
```

## Ambiente Local (.venv)

### macOS / Linux

1) Criar e ativar ambiente virtual

```bash
python3 -m venv .venv
source .venv/bin/activate
```

2) Instalar depend√™ncias

```bash
python -m pip install --upgrade pip
pip install -r requirements.txt
```

## Checklist do Projeto - Datathon Machine Learning Engineering

Este checklist foi elaborado considerando explicitamente as inconsist√™ncias reais do dataset fornecido (schemas distintos entre anos, colunas duplicadas, valores inv√°lidos, mudan√ßas sem√¢nticas de campos e interse√ß√£o parcial de estudantes entre per√≠odos). As etapas descritas adotam pr√°ticas de Data Engineering e MLOps para garantir robustez, reprodutibilidade e validade estat√≠stica do modelo em produ√ß√£o.

Status: `TODO` | `DOING` | `DONE` | `BLOCKED`

Progresso geral (barra visual):
`[üü©üü©üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú]`

`8 de 92 tarefas conclu√≠das (8.7%)`

| Fase | Progresso |
|---|---|
| Fase 1 - Entendimento do Problema e Target | 0/11 |
| Fase 2 - Organiza√ß√£o do Projeto e Ambiente | 2/7 |
| Fase 3 - Ingest√£o, Qualidade e Governan√ßa de Dados | 0/14 |
| Fase 4 - Pr√©-processamento e Engenharia de Features | 0/10 |
| Fase 5 - Pipeline, Treinamento e Avalia√ß√£o | 0/17 |
| Fase 6 - Artefatos, API e Deploy | 0/12 |
| Fase 7 - Testes, Monitoramento e Dashboard | 0/7 |
| Fase 8 - Documenta√ß√£o e Entrega Final | 6/14 |
| Total | 8/92 |

### Fase 1 - Entendimento do Problema e Target [0/11]
- [ ] Compreender o objetivo de neg√≥cio: prever o risco de defasagem escolar (t+1)
- [ ] Estudar o dicion√°rio de dados e as bases de 2022, 2023 e 2024
- [ ] Padronizar a coluna de defasagem (`Defas` -> `Defasagem`)
- [ ] Definir a formula√ß√£o do target bin√°rio
- [ ] Definir m√©trica prim√°ria de sucesso (`Recall`) e m√©tricas secund√°rias (`PR-AUC`, `Precision`, `F1`, `ROC-AUC`) j√° na fase de desenho
- [ ] Definir `y = 1` se `Defasagem_{t+1} < 0`
- [ ] Definir `y = 0` caso contr√°rio
- [ ] Definir a estrat√©gia de pares temporais
- [ ] Definir treino: `X(2022) -> y(2023)`
- [ ] Definir holdout final: `X(2023) -> y(2024)`
- [ ] Garantir que `RA` seja usado apenas como ID, nunca como feature

### Fase 2 - Organiza√ß√£o do Projeto e Ambiente [2/7]
- [x] Configurar `.gitignore` inicial (ignorar `agents.md`, `dataset/` e `.DS_Store`)
- [x] Expandir `.gitignore` com padr√µes essenciais de Python/MLOps (cache, venv, cobertura, builds, logs e segredos locais)
- [ ] Criar estrutura de diret√≥rios do projeto
- [ ] Criar `requirements.txt` com depend√™ncias m√≠nimas
- [ ] Fixar vers√µes das depend√™ncias para garantir reprodutibilidade do ambiente de execu√ß√£o
- [ ] Definir `random_state` global para reprodutibilidade
- [ ] Configurar logging b√°sico do projeto

### Fase 3 - Ingest√£o, Qualidade e Governan√ßa de Dados [0/14]
Camadas conceituais desta fase:
- Camada A - Pr√©-ingest√£o e Ingest√£o: contrato de dados, mapeamento de colunas equivalentes, tratamento de headers duplicados, normaliza√ß√£o de valores inv√°lidos, padroniza√ß√£o de datas e normaliza√ß√£o sem√¢ntica.
- Camada B - Governan√ßa e Valida√ß√£o Cont√≠nua: coorte temporal por `RA`, valida√ß√µes de shift, versionamento de dataset e privacidade operacional.

Nota de coorte temporal:
> A constru√ß√£o dos pares temporais considera apenas estudantes presentes em ambos os anos consecutivos (`t` e `t+1`), evitando vi√©s por evas√£o ou entrada tardia e garantindo consist√™ncia estat√≠stica na defini√ß√£o do target.

- [ ] Implementar leitura do arquivo XLSX
- [ ] Tratar diferen√ßas de colunas entre os anos
- [ ] Padronizar nomes e tipos de dados
- [ ] Criar fun√ß√£o de gera√ß√£o dos pares temporais (`t -> t+1`)
- [ ] Validar consist√™ncia dos dados (missing, tipos inv√°lidos)
- [ ] Definir um data contract por ano (nome, tipo e dom√≠nio esperado por coluna)
- [ ] Implementar valida√ß√£o autom√°tica do data contract (asserts de nome, tipo e dom√≠nio por coluna)
- [ ] Criar tabela de mapeamento entre colunas equivalentes (`Matem/Portug/Ingl√™s` <-> `Mat/Por/Ing`; `Defas` <-> `Defasagem`)
- [ ] Tratar headers duplicados na ingest√£o com regra determin√≠stica
- [ ] Normalizar valores inv√°lidos em campos num√©ricos (ex.: `#N/A`, `#DIV/0!`, `INCLUIR`)
- [ ] Padronizar datas de nascimento para formato √∫nico
- [ ] Normalizar categorias textuais entre anos (`Menina/Menino` <-> `Feminino/Masculino`; `Escola P√∫blica` <-> `P√∫blica`)
- [ ] Definir regra formal de coorte temporal por `RA` (entradas, sa√≠das e interse√ß√µes por ano)
- [ ] Gerar e registrar estat√≠sticas de interse√ß√£o por `RA` entre anos (contagem absoluta e percentual)

### Fase 4 - Pr√©-processamento e Engenharia de Features [0/10]
- [ ] Separar features num√©ricas e categ√≥ricas
- [ ] Tratar valores ausentes (imputa√ß√£o)
- [ ] Codificar vari√°veis categ√≥ricas (`OneHotEncoder` ou similar)
- [ ] Escalonar vari√°veis num√©ricas (se necess√°rio)
- [ ] Garantir que o pr√©-processamento seja reutiliz√°vel na infer√™ncia
- [ ] Criar novas features relevantes (se aplic√°vel)
- [ ] Implementar checagem expl√≠cita de data leakage (lista negra de colunas futuras + asserts temporais)
- [ ] Remover colunas irrelevantes ou com leakage
- [ ] Garantir que nenhuma feature use informa√ß√£o futura
- [ ] Documentar as principais decis√µes de feature engineering

### Fase 5 - Pipeline, Treinamento e Avalia√ß√£o [0/17]
Nota de shift temporal:
> Antes do treinamento final, √© realizada uma an√°lise de shift temporal do target e das features, uma vez que a preval√™ncia da classe positiva varia significativamente entre os per√≠odos analisados (aprox. `61%` para `40%`).

- [ ] Criar `ColumnTransformer` para pr√©-processamento
- [ ] Encapsular tudo em uma `Pipeline` do scikit-learn
- [ ] Garantir consist√™ncia treino vs infer√™ncia
- [ ] Validar que a pipeline aceita dados crus da API
- [ ] Treinar modelo baseline (`Logistic Regression`)
- [ ] Treinar modelo n√£o-linear (ex.: `HistGradientBoosting`)
- [ ] Usar apenas dados de treino (`2022 -> 2023`)
- [ ] (Opcional) Valida√ß√£o interna (CV estratificada)
- [ ] Definir estrat√©gia expl√≠cita para desbalanceamento de classes (`class_weight`, ajuste de threshold ou decis√£o justificada de n√£o tratar)
- [ ] Comparar modelos com foco em Recall e PR-AUC
- [ ] Avaliar desempenho no holdout temporal (`2023 -> 2024`)
- [ ] Calcular m√©tricas: Recall, Precision, F1-score, ROC-AUC, PR-AUC
- [ ] Gerar matriz de confus√£o
- [ ] Definir threshold operacional focado em Recall
- [ ] Definir crit√©rio objetivo formal de sele√ß√£o do modelo final (ex.: maior Recall com PR-AUC acima de limiar m√≠nimo)
- [ ] Justificar escolha do modelo final
- [ ] Incluir valida√ß√£o de shift temporal do target e das features antes do treinamento final

### Fase 6 - Artefatos, API e Deploy [0/12]
- [ ] Salvar pipeline completa em `model.joblib`
- [ ] Criar `metadata.json` com modelo, m√©tricas, threshold, features esperadas, data do treino e vers√µes das bibliotecas
- [ ] Salvar dados de refer√™ncia para monitoramento de drift
- [ ] Versionar dataset de treino/valida√ß√£o (`hash/checksum` + vers√£o usada no experimento)
- [ ] Definir schema formal de sa√≠da do modelo/API (probabilidade, classe prevista, threshold aplicado e vers√£o do modelo)
- [ ] Criar aplica√ß√£o FastAPI
- [ ] Implementar endpoint `POST /predict`
- [ ] Implementar `GET /health` e `GET /version`
- [ ] Validar entradas com Pydantic
- [ ] Garantir carregamento do modelo salvo
- [ ] Criar Dockerfile enxuto baseado em `python:slim`
- [ ] Documentar comandos de build e run no README

### Fase 7 - Testes, Monitoramento e Dashboard [0/7]
- [ ] Criar testes unit√°rios e de integra√ß√£o com pytest
- [ ] Garantir cobertura m√≠nima de 80% com `pytest-cov`
- [ ] Implementar teste de n√£o-regress√£o do modelo com limiares m√≠nimos de m√©tricas (ex.: Recall e/ou PR-AUC)
- [ ] Configurar logging estruturado
- [ ] Aplicar pol√≠tica de privacidade operacional (n√£o logar identificadores sens√≠veis como `RA` em API e monitoramento)
- [ ] Implementar relat√≥rio de drift com Evidently
- [ ] Criar aplica√ß√£o Streamlit para visualiza√ß√£o do relat√≥rio de drift

### Fase 8 - Documenta√ß√£o e Entrega Final [6/14]
- [x] Documentar vis√£o geral do problema e objetivo
- [ ] Documentar stack tecnol√≥gica
- [ ] Documentar estrutura do projeto
- [ ] Documentar etapas do pipeline de Machine Learning
- [ ] Documentar limita√ß√µes conhecidas do modelo e riscos assumidos
- [ ] Documentar exemplos de chamadas √† API
- [x] Documentar setup de ambiente local com `.venv` e instala√ß√£o de depend√™ncias
- [ ] Publicar c√≥digo organizado no GitHub
- [ ] Disponibilizar API acess√≠vel localmente
- [ ] Gravar v√≠deo gerencial (<= 5 minutos) explicando a solu√ß√£o
- [x] Criar `agents.md` com conven√ß√µes operacionais para agentes LLM
- [x] Adicionar barra de progresso geral visual (`[üü©‚¨ú...]`) no checklist
- [x] Atualizar `agents.md` com regra expl√≠cita de manuten√ß√£o da barra visual e da contagem geral
- [x] Incorporar recomenda√ß√µes da revis√£o t√©cnica do checklist (gaps de maturidade por fase)

<details>
<summary>Notas de uso do checklist</summary>

- Atualize os contadores de progresso de cada fase ao concluir tarefas.
- Atualize a barra visual de progresso geral (`[üü©‚¨ú...]`) com base na porcentagem conclu√≠da.
- Marque uma tarefa como `DOING` no texto do item quando estiver em andamento.
- Promova para `DONE` apenas ap√≥s evid√™ncia (teste, artefato, log ou documenta√ß√£o).
- Use `BLOCKED` quando depender de decis√£o, dado externo ou ajuste de escopo.

</details>
