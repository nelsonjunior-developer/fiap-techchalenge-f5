



## Vis√£o Geral e Objetivo de Neg√≥cio

### 1) Declara√ß√£o formal do objetivo
O objetivo deste projeto √© desenvolver um modelo de Machine Learning capaz de prever o risco de um estudante apresentar defasagem escolar no pr√≥ximo ano letivo (`t+1`), utilizando exclusivamente informa√ß√µes dispon√≠veis at√© o ano corrente (`t`). A previs√£o tem car√°ter preventivo e visa apoiar decis√µes educacionais da Associa√ß√£o Passos M√°gicos, priorizando alunos com maior risco.

### 2) Enquadramento do problema de Machine Learning
- Problema de `classifica√ß√£o bin√°ria` (risco vs. n√£o risco).
- Foco em `estimativa de risco futuro`, e n√£o em explica√ß√£o retrospectiva.
- Uso de dados futuros √© proibido para evitar `data leakage`.

### 3) Interpreta√ß√£o de neg√≥cio da defasagem escolar
No contexto da institui√ß√£o, defasagem escolar representa desalinhamento entre o n√≠vel educacional esperado e o n√≠vel efetivamente observado no estudante. Valores negativos indicam maior atraso em rela√ß√£o ao esperado e, portanto, maior risco educacional. O interesse de neg√≥cio est√° em antecipar essa condi√ß√£o no ano seguinte para permitir interven√ß√£o preventiva.
No dataset operacional, essa condi√ß√£o √© representada nos campos `Defas`/`Defasagem`, usados como refer√™ncia de risco educacional no recorte temporal.

### 4) Contexto de uso da previs√£o
- Usu√°rios potenciais: coordena√ß√£o pedag√≥gica, equipe psicopedag√≥gica e gest√£o educacional.
- Uso principal: prioriza√ß√£o de acompanhamento preventivo e aloca√ß√£o de suporte para alunos em risco.
- Decis√£o de risco: falsos negativos t√™m custo maior que falsos positivos, pois deixam de sinalizar alunos que precisariam de interven√ß√£o.
O modelo tem car√°ter preditivo e n√£o causal, sendo utilizado exclusivamente como ferramenta de apoio √† decis√£o humana.

### 5) Implica√ß√µes t√©cnicas assumidas nesta fase
- Horizonte temporal adotado: `t -> t+1`.
- Tipo de problema: `classifica√ß√£o bin√°ria`.
- M√©trica priorit√°ria: `Recall` (minimiza√ß√£o de falsos negativos).
- Sa√≠da esperada do modelo: `probabilidade de risco` (com posterior aplica√ß√£o de threshold operacional).
- Coorte temporal: pares v√°lidos consideram estudantes com `RA` presente em anos consecutivos (`t` e `t+1`).

## An√°lise das Bases e Dicion√°rio

A an√°lise detalhada do dicion√°rio de dados e das bases `2022`, `2023` e `2024` est√° documentada em:

- [docs/analise_bases_e_dicionario.md](docs/analise_bases_e_dicionario.md)
- Regra de ingest√£o aplicada: `Defas` (2022) √© padronizada para `Defasagem` para manter schema √∫nico entre anos.

## üìÅ Estrutura do Projeto

O reposit√≥rio √© organizado para separar claramente ingest√£o e tratamento de dados, treinamento do modelo, disponibiliza√ß√£o via API, monitoramento e testes, garantindo manutenibilidade, reprodutibilidade e facilidade de deploy.

```
raiz-do-projeto/
‚îÇ
‚îú‚îÄ‚îÄ app/                         # Camada da API (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # Ponto de entrada da aplica√ß√£o FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ routes.py                # Rotas da API (/predict, /health, /version)
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py               # Schemas de requisi√ß√£o/resposta (Pydantic)
‚îÇ   ‚îî‚îÄ‚îÄ model/
‚îÇ       ‚îú‚îÄ‚îÄ model.joblib         # Pipeline de ML treinada (serializada)
‚îÇ       ‚îú‚îÄ‚îÄ metadata.json        # Metadados do modelo (m√©tricas, threshold, vers√£o)
‚îÇ       ‚îî‚îÄ‚îÄ reference_data.csv   # Dataset de refer√™ncia para monitoramento de drift
‚îÇ
‚îú‚îÄ‚îÄ src/                         # Pipeline principal de ML
‚îÇ   ‚îú‚îÄ‚îÄ data.py                  # Carrega XLSX, padroniza colunas e cria pares t‚Üít+1
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py         # Limpeza, codifica√ß√£o e escalonamento de dados
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py   # Cria√ß√£o e sele√ß√£o de atributos
‚îÇ   ‚îú‚îÄ‚îÄ train.py                 # Treinamento do modelo e valida√ß√£o interna
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py              # M√©tricas, matriz de confus√£o e sele√ß√£o de threshold
‚îÇ   ‚îú‚îÄ‚îÄ drift.py                 # Detec√ß√£o de drift com Evidently
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                 # Utilit√°rios compartilhados (logging, configs, helpers)
‚îÇ
‚îú‚îÄ‚îÄ dashboards/
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py         # Dashboard Streamlit para visualizar relat√≥rios de drift
‚îÇ
‚îú‚îÄ‚îÄ tests/                       # Testes unit√°rios e de integra√ß√£o (pytest)
‚îÇ   ‚îú‚îÄ‚îÄ test_data.py             # Testes da carga de dados e pareamento temporal
‚îÇ   ‚îú‚îÄ‚îÄ test_preprocessing.py    # Testes das etapas de pr√©-processamento
‚îÇ   ‚îú‚îÄ‚îÄ test_feature_engineering.py
‚îÇ   ‚îú‚îÄ‚îÄ test_train_smoke.py      # Smoke test da pipeline de treinamento
‚îÇ   ‚îî‚îÄ‚îÄ test_api_predict.py      # Testes do endpoint da API (/predict)
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                   # (Opcional) An√°lises explorat√≥rias e experimentos
‚îÇ
‚îú‚îÄ‚îÄ Dockerfile                   # Defini√ß√£o da imagem Docker para deploy da API
‚îú‚îÄ‚îÄ requirements.txt             # Depend√™ncias Python
‚îú‚îÄ‚îÄ README.md                    # Documenta√ß√£o do projeto
‚îî‚îÄ‚îÄ .gitignore                   # Regras de arquivos ignorados no Git
```

## Ambiente Local (.venv)

### macOS / Linux

1) Criar e ativar ambiente virtual

```bash
python3 -m venv .venv
source .venv/bin/activate
```

2) Instalar depend√™ncias

```bash
python -m pip install --upgrade pip
pip install -r requirements.txt
```

### Execu√ß√£o de Testes

1) Instalar depend√™ncias de desenvolvimento

```bash
source .venv/bin/activate
pip install -r requirements-dev.txt
```

2) Rodar su√≠te de testes

```bash
pytest -q
```

3) Rodar testes com cobertura (comando oficial do projeto)

```bash
pytest --cov=src --cov-report=term-missing --cov-fail-under=80
```

Observa√ß√£o: mantenha este comando de cobertura sempre documentado no `README.md` para padronizar valida√ß√£o local e evid√™ncia t√©cnica da entrega.

## Checklist do Projeto - Datathon Machine Learning Engineering

Este checklist foi elaborado considerando explicitamente as inconsist√™ncias reais do dataset fornecido (schemas distintos entre anos, colunas duplicadas, valores inv√°lidos, mudan√ßas sem√¢nticas de campos e interse√ß√£o parcial de estudantes entre per√≠odos). As etapas descritas adotam pr√°ticas de Data Engineering e MLOps para garantir robustez, reprodutibilidade e validade estat√≠stica do modelo em produ√ß√£o.

Status: `TODO` | `DOING` | `DONE` | `BLOCKED`

Progresso geral (barra visual):
`[üü©üü©üü©üü©üü©üü©üü©üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú]`

`18 de 95 tarefas conclu√≠das (18.9%)`

| Fase | Progresso |
|---|---|
| Fase 1 - Entendimento do Problema e Target | 3/11 |
| Fase 2 - Organiza√ß√£o do Projeto e Ambiente | 4/7 |
| Fase 3 - Ingest√£o, Qualidade e Governan√ßa de Dados | 0/14 |
| Fase 4 - Pr√©-processamento e Engenharia de Features | 0/10 |
| Fase 5 - Pipeline, Treinamento e Avalia√ß√£o | 0/17 |
| Fase 6 - Artefatos, API e Deploy | 0/12 |
| Fase 7 - Testes, Monitoramento e Dashboard | 1/7 |
| Fase 8 - Documenta√ß√£o e Entrega Final | 10/15 |
| Total | 18/95 |

### Fase 1 - Entendimento do Problema e Target [3/11]
- [x] Compreender o objetivo de neg√≥cio: prever o risco de defasagem escolar (t+1)
- [x] Estudar o dicion√°rio de dados e as bases de 2022, 2023 e 2024
- [x] Padronizar a coluna de defasagem (`Defas` -> `Defasagem`)
- [ ] Definir a formula√ß√£o do target bin√°rio
- [ ] Definir m√©trica prim√°ria de sucesso (`Recall`) e m√©tricas secund√°rias (`PR-AUC`, `Precision`, `F1`, `ROC-AUC`) j√° na fase de desenho
- [ ] Definir `y = 1` se `Defasagem_{t+1} < 0`
- [ ] Definir `y = 0` caso contr√°rio
- [ ] Definir a estrat√©gia de pares temporais
- [ ] Definir treino: `X(2022) -> y(2023)`
- [ ] Definir holdout final: `X(2023) -> y(2024)`
- [ ] Garantir que `RA` seja usado apenas como ID, nunca como feature

### Fase 2 - Organiza√ß√£o do Projeto e Ambiente [4/7]
- [x] Configurar `.gitignore` inicial (ignorar `agents.md`, `dataset/` e `.DS_Store`)
- [x] Expandir `.gitignore` com padr√µes essenciais de Python/MLOps (cache, venv, cobertura, builds, logs e segredos locais)
- [ ] Criar estrutura de diret√≥rios do projeto
- [x] Criar `requirements.txt` com depend√™ncias m√≠nimas
- [x] Fixar vers√µes das depend√™ncias para garantir reprodutibilidade do ambiente de execu√ß√£o
- [ ] Definir `random_state` global para reprodutibilidade
- [ ] Configurar logging b√°sico do projeto

### Fase 3 - Ingest√£o, Qualidade e Governan√ßa de Dados [0/14]
Camadas conceituais desta fase:
- Camada A - Pr√©-ingest√£o e Ingest√£o: contrato de dados, mapeamento de colunas equivalentes, tratamento de headers duplicados, normaliza√ß√£o de valores inv√°lidos, padroniza√ß√£o de datas e normaliza√ß√£o sem√¢ntica.
- Camada B - Governan√ßa e Valida√ß√£o Cont√≠nua: coorte temporal por `RA`, valida√ß√µes de shift, versionamento de dataset e privacidade operacional.

Nota de coorte temporal:
> A constru√ß√£o dos pares temporais considera apenas estudantes presentes em ambos os anos consecutivos (`t` e `t+1`), evitando vi√©s por evas√£o ou entrada tardia e garantindo consist√™ncia estat√≠stica na defini√ß√£o do target.

- [ ] Implementar leitura do arquivo XLSX
- [ ] Tratar diferen√ßas de colunas entre os anos
- [ ] Padronizar nomes e tipos de dados
- [ ] Criar fun√ß√£o de gera√ß√£o dos pares temporais (`t -> t+1`)
- [ ] Validar consist√™ncia dos dados (missing, tipos inv√°lidos)
- [ ] Definir um data contract por ano (nome, tipo e dom√≠nio esperado por coluna)
- [ ] Implementar valida√ß√£o autom√°tica do data contract (asserts de nome, tipo e dom√≠nio por coluna)
- [ ] Criar tabela de mapeamento entre colunas equivalentes (`Matem/Portug/Ingl√™s` <-> `Mat/Por/Ing`; `Defas` <-> `Defasagem`)
- [ ] Tratar headers duplicados na ingest√£o com regra determin√≠stica
- [ ] Normalizar valores inv√°lidos em campos num√©ricos (ex.: `#N/A`, `#DIV/0!`, `INCLUIR`)
- [ ] Padronizar datas de nascimento para formato √∫nico
- [ ] Normalizar categorias textuais entre anos (`Menina/Menino` <-> `Feminino/Masculino`; `Escola P√∫blica` <-> `P√∫blica`)
- [ ] Definir regra formal de coorte temporal por `RA` (entradas, sa√≠das e interse√ß√µes por ano)
- [ ] Gerar e registrar estat√≠sticas de interse√ß√£o por `RA` entre anos (contagem absoluta e percentual)

### Fase 4 - Pr√©-processamento e Engenharia de Features [0/10]
- [ ] Separar features num√©ricas e categ√≥ricas
- [ ] Tratar valores ausentes (imputa√ß√£o)
- [ ] Codificar vari√°veis categ√≥ricas (`OneHotEncoder` ou similar)
- [ ] Escalonar vari√°veis num√©ricas (se necess√°rio)
- [ ] Garantir que o pr√©-processamento seja reutiliz√°vel na infer√™ncia
- [ ] Criar novas features relevantes (se aplic√°vel)
- [ ] Implementar checagem expl√≠cita de data leakage (lista negra de colunas futuras + asserts temporais)
- [ ] Remover colunas irrelevantes ou com leakage
- [ ] Garantir que nenhuma feature use informa√ß√£o futura
- [ ] Documentar as principais decis√µes de feature engineering

### Fase 5 - Pipeline, Treinamento e Avalia√ß√£o [0/17]
Nota de shift temporal:
> Antes do treinamento final, √© realizada uma an√°lise de shift temporal do target e das features, uma vez que a preval√™ncia da classe positiva varia significativamente entre os per√≠odos analisados (aprox. `61%` para `40%`).

- [ ] Criar `ColumnTransformer` para pr√©-processamento
- [ ] Encapsular tudo em uma `Pipeline` do scikit-learn
- [ ] Garantir consist√™ncia treino vs infer√™ncia
- [ ] Validar que a pipeline aceita dados crus da API
- [ ] Treinar modelo baseline (`Logistic Regression`)
- [ ] Treinar modelo n√£o-linear (ex.: `HistGradientBoosting`)
- [ ] Usar apenas dados de treino (`2022 -> 2023`)
- [ ] (Opcional) Valida√ß√£o interna (CV estratificada)
- [ ] Definir estrat√©gia expl√≠cita para desbalanceamento de classes (`class_weight`, ajuste de threshold ou decis√£o justificada de n√£o tratar)
- [ ] Comparar modelos com foco em Recall e PR-AUC
- [ ] Avaliar desempenho no holdout temporal (`2023 -> 2024`)
- [ ] Calcular m√©tricas: Recall, Precision, F1-score, ROC-AUC, PR-AUC
- [ ] Gerar matriz de confus√£o
- [ ] Definir threshold operacional focado em Recall
- [ ] Definir crit√©rio objetivo formal de sele√ß√£o do modelo final (ex.: maior Recall com PR-AUC acima de limiar m√≠nimo)
- [ ] Justificar escolha do modelo final
- [ ] Incluir valida√ß√£o de shift temporal do target e das features antes do treinamento final

### Fase 6 - Artefatos, API e Deploy [0/12]
- [ ] Salvar pipeline completa em `model.joblib`
- [ ] Criar `metadata.json` com modelo, m√©tricas, threshold, features esperadas, data do treino e vers√µes das bibliotecas
- [ ] Salvar dados de refer√™ncia para monitoramento de drift
- [ ] Versionar dataset de treino/valida√ß√£o (`hash/checksum` + vers√£o usada no experimento)
- [ ] Definir schema formal de sa√≠da do modelo/API (probabilidade, classe prevista, threshold aplicado e vers√£o do modelo)
- [ ] Criar aplica√ß√£o FastAPI
- [ ] Implementar endpoint `POST /predict`
- [ ] Implementar `GET /health` e `GET /version`
- [ ] Validar entradas com Pydantic
- [ ] Garantir carregamento do modelo salvo
- [ ] Criar Dockerfile enxuto baseado em `python:slim`
- [ ] Documentar comandos de build e run no README

### Fase 7 - Testes, Monitoramento e Dashboard [1/7]
- [ ] Criar testes unit√°rios e de integra√ß√£o com pytest
- [x] Garantir cobertura m√≠nima de 80% com `pytest-cov`
- [ ] Implementar teste de n√£o-regress√£o do modelo com limiares m√≠nimos de m√©tricas (ex.: Recall e/ou PR-AUC)
- [ ] Configurar logging estruturado
- [ ] Aplicar pol√≠tica de privacidade operacional (n√£o logar identificadores sens√≠veis como `RA` em API e monitoramento)
- [ ] Implementar relat√≥rio de drift com Evidently
- [ ] Criar aplica√ß√£o Streamlit para visualiza√ß√£o do relat√≥rio de drift

### Fase 8 - Documenta√ß√£o e Entrega Final [10/15]
- [x] Documentar vis√£o geral do problema e objetivo
- [ ] Documentar stack tecnol√≥gica
- [x] Documentar estrutura do projeto
- [ ] Documentar etapas do pipeline de Machine Learning
- [ ] Documentar limita√ß√µes conhecidas do modelo e riscos assumidos
- [ ] Documentar exemplos de chamadas √† API
- [x] Documentar setup de ambiente local com `.venv` e instala√ß√£o de depend√™ncias
- [ ] Publicar c√≥digo organizado no GitHub
- [ ] Disponibilizar API acess√≠vel localmente
- [ ] Gravar v√≠deo gerencial (<= 5 minutos) explicando a solu√ß√£o
- [x] Criar `agents.md` com conven√ß√µes operacionais para agentes LLM
- [x] Adicionar barra de progresso geral visual (`[üü©‚¨ú...]`) no checklist
- [x] Atualizar `agents.md` com regra expl√≠cita de manuten√ß√£o da barra visual e da contagem geral
- [x] Incorporar recomenda√ß√µes da revis√£o t√©cnica do checklist (gaps de maturidade por fase)
- [x] Refinar reda√ß√£o do objetivo para "apresentar defasagem no t+1" (evita ambiguidade de transi√ß√£o vs estado)
- [x] Refinar vis√£o geral com v√≠nculo expl√≠cito a `Defas/Defasagem` e regra de coorte por `RA`
- [x] Adicionar men√ß√£o expl√≠cita de n√£o-causalidade do modelo na se√ß√£o de contexto de uso

<details>
<summary>Notas de uso do checklist</summary>

- Atualize os contadores de progresso de cada fase ao concluir tarefas.
- Atualize a barra visual de progresso geral (`[üü©‚¨ú...]`) com base na porcentagem conclu√≠da.
- Marque uma tarefa como `DOING` no texto do item quando estiver em andamento.
- Promova para `DONE` apenas ap√≥s evid√™ncia (teste, artefato, log ou documenta√ß√£o).
- Use `BLOCKED` quando depender de decis√£o, dado externo ou ajuste de escopo.

</details>
