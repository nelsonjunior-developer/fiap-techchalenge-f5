



## Vis√£o Geral e Objetivo de Neg√≥cio

### 1) Declara√ß√£o formal do objetivo
O objetivo deste projeto √© desenvolver um modelo de Machine Learning capaz de prever o risco de um estudante apresentar defasagem escolar no pr√≥ximo ano letivo (`t+1`), utilizando exclusivamente informa√ß√µes dispon√≠veis at√© o ano corrente (`t`). A previs√£o tem car√°ter preventivo e visa apoiar decis√µes educacionais da Associa√ß√£o Passos M√°gicos, priorizando alunos com maior risco.

### 2) Enquadramento do problema de Machine Learning
- Problema de `classifica√ß√£o bin√°ria` (risco vs. n√£o risco).
- Foco em `estimativa de risco futuro`, e n√£o em explica√ß√£o retrospectiva.
- Uso de dados futuros √© proibido para evitar `data leakage`.

### 3) Interpreta√ß√£o de neg√≥cio da defasagem escolar
No contexto da institui√ß√£o, defasagem escolar representa desalinhamento entre o n√≠vel educacional esperado e o n√≠vel efetivamente observado no estudante. Valores negativos indicam maior atraso em rela√ß√£o ao esperado e, portanto, maior risco educacional. O interesse de neg√≥cio est√° em antecipar essa condi√ß√£o no ano seguinte para permitir interven√ß√£o preventiva.
No dataset operacional, essa condi√ß√£o √© representada nos campos `Defas`/`Defasagem`, usados como refer√™ncia de risco educacional no recorte temporal.

### 4) Contexto de uso da previs√£o
- Usu√°rios potenciais: coordena√ß√£o pedag√≥gica, equipe psicopedag√≥gica e gest√£o educacional.
- Uso principal: prioriza√ß√£o de acompanhamento preventivo e aloca√ß√£o de suporte para alunos em risco.
- Decis√£o de risco: falsos negativos t√™m custo maior que falsos positivos, pois deixam de sinalizar alunos que precisariam de interven√ß√£o.
O modelo tem car√°ter preditivo e n√£o causal, sendo utilizado exclusivamente como ferramenta de apoio √† decis√£o humana.

### 5) Implica√ß√µes t√©cnicas assumidas nesta fase
- Horizonte temporal adotado: `t -> t+1`.
- Tipo de problema: `classifica√ß√£o bin√°ria`.
- M√©trica priorit√°ria: `Recall` (minimiza√ß√£o de falsos negativos).
- Sa√≠da esperada do modelo: `probabilidade de risco` (com posterior aplica√ß√£o de threshold operacional).
- Coorte temporal: pares v√°lidos consideram estudantes com `RA` presente em anos consecutivos (`t` e `t+1`).

## Defini√ß√£o do Target

- Regra formal do target bin√°rio:
  - `y = 1` se `Defasagem_{t+1} < 0`
  - `y = 0` caso contr√°rio
- Comparador adotado: estritamente `< 0`.
- Recorte temporal oficial:
  - Treino: `X(2022) -> y(2023)`
  - Holdout final: `X(2023) -> y(2024)`
- Pol√≠tica para qualidade do target em `t+1`:
  - Tokens inv√°lidos (ex.: `#N/A`, `#DIV/0!`, `INCLUIR`) s√£o convertidos para `NaN` antes da defini√ß√£o de `y`.
  - Pares com target ausente/inv√°lido s√£o exclu√≠dos.
  - As contagens de exclus√£o por `missing` e `invalid` s√£o registradas em log.
- Regra de coorte por `RA`:
  - Apenas estudantes presentes em ambos os anos consecutivos (`t` e `t+1`) entram nos pares temporais.
- Regra anti-leakage:
  - `X` usa somente vari√°veis de `t`.
  - `y` √© calculado exclusivamente com `Defasagem` de `t+1`.
  - `RA` √© usado apenas como identificador/auditoria, nunca como feature.
  - O dataset de pares temporais implementa valida√ß√µes anti-leakage e falha caso colunas do ano `t+1` vazem para `X` (ex.: sufixos de merge).
- A m√©trica prim√°ria de sucesso √© Recall (minimizar falsos negativos). Como m√©tricas secund√°rias de acompanhamento e trade-off, reportamos PR-AUC (Average Precision), Precision, F1-score e ROC-AUC.

## An√°lise das Bases e Dicion√°rio

A an√°lise detalhada do dicion√°rio de dados e das bases `2022`, `2023` e `2024` est√° documentada em:

- [docs/analise_bases_e_dicionario.md](docs/analise_bases_e_dicionario.md)
- Regra de ingest√£o aplicada: `Defas` (2022) √© padronizada para `Defasagem` para manter schema √∫nico entre anos.

## Dados e Ingest√£o

- O arquivo XLSX do projeto cont√©m as abas `PEDE2022`, `PEDE2023` e `PEDE2024`.
- O caminho do arquivo pode ser configurado via `DATASET_PATH`.
- A leitura raw foi separada da padroniza√ß√£o:
  - `load_pede_workbook_raw` / `load_year_sheet_raw`: apenas leitura.
  - `load_pede_workbook` / `load_year_sheet`: wrappers com padroniza√ß√£o.
- A harmoniza√ß√£o de schema usa nomes can√¥nicos entre anos, incluindo:
  - `Defas -> Defasagem`
  - `Matem -> Mat`, `Portug -> Por`, `Ingl√™s -> Ing`
  - `Idade 22 -> Idade`
  - `Fase ideal/Fase Ideal -> Fase_Ideal`
  - `Nome/Nome Anonimizado -> Nome_Anon`
  - `Ano nasc/Data de Nasc -> Data_Nasc`
- Regras de fallback para colunas can√¥nicas derivadas:
  - `INDE` por ano:
    - 2022: `INDE 22`
    - 2023: `INDE 2023` -> `INDE 23` -> `INDE 22`
    - 2024: `INDE 2024` -> `INDE 23` -> `INDE 22`
  - `Pedra_Ano` por ano:
    - 2022: `Pedra 22` -> `Pedra 21` -> `Pedra 20`
    - 2023: `Pedra 2023` -> `Pedra 23` -> `Pedra 22`
    - 2024: `Pedra 2024` -> `Pedra 23` -> `Pedra 22`
- Duplicadas de planilha (`.1`, `.2`, ...) s√£o tratadas de forma determin√≠stica como `__dupN`, sem perda silenciosa.
- Nota sem√¢ntica importante:
  - `Ano nasc` e `Data de Nasc` n√£o s√£o semanticamente id√™nticos (ano vs data completa). Nesta fase harmonizamos apenas header; normaliza√ß√£o de conte√∫do ser√° feita depois.
  - `Nome` e `Nome Anonimizado` s√£o harmonizados para `Nome_Anon` apenas para alinhamento de schema; isso n√£o garante anonimiza√ß√£o no dado de 2022.
- Padroniza√ß√£o de tipos ap√≥s harmoniza√ß√£o/alinhamento:
  - `Data_Nasc` √© padronizada para `datetime` com desambigua√ß√£o expl√≠cita:
    - valores num√©ricos em `1900..2100` s√£o interpretados como ano (`YYYY-01-01`)
    - demais num√©ricos s√£o interpretados como serial Excel (`origin=1899-12-30`)
  - `Idade` √© sanitizada para remover valores datetime (ex.: `1900-01-...`, que viram `NaN`) e convertida para `Int64` (nullable).
  - Colunas num√©ricas usam dtypes nulos est√°veis (`Float64`/`Int64`) com coer√ß√£o robusta (`to_numeric(..., errors=\"coerce\")`), incluindo tratamento do token `INCLUIR`.
  - Colunas categ√≥ricas s√£o padronizadas para `string` com `strip`.

## üìÅ Estrutura do Projeto

O reposit√≥rio √© organizado para separar claramente ingest√£o e tratamento de dados, treinamento do modelo, disponibiliza√ß√£o via API, monitoramento e testes, garantindo manutenibilidade, reprodutibilidade e facilidade de deploy.

```
raiz-do-projeto/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ requirements-dev.txt
‚îú‚îÄ‚îÄ agents.md
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ model/
‚îÇ       ‚îî‚îÄ‚îÄ .gitkeep
‚îú‚îÄ‚îÄ artifacts/
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep
‚îú‚îÄ‚îÄ dashboards/
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ .gitkeep
‚îÇ   ‚îî‚îÄ‚îÄ analise_bases_e_dicionario.md
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ data.py
‚îÇ   ‚îú‚îÄ‚îÄ dtypes.py
‚îÇ   ‚îú‚îÄ‚îÄ schema.py
‚îÇ   ‚îî‚îÄ‚îÄ utils.py
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ conftest.py
    ‚îú‚îÄ‚îÄ test_config.py
    ‚îú‚îÄ‚îÄ test_data.py
    ‚îú‚îÄ‚îÄ test_dtypes.py
    ‚îú‚îÄ‚îÄ test_logging.py
    ‚îî‚îÄ‚îÄ test_schema.py
```

## Ambiente Local (.venv)

### macOS / Linux

1) Criar e ativar ambiente virtual

```bash
python3 -m venv .venv
source .venv/bin/activate
```

2) Instalar depend√™ncias

```bash
python -m pip install --upgrade pip
pip install -r requirements.txt
```

Reprodutibilidade: `RANDOM_STATE = 42` √© usado globalmente no projeto.

### Execu√ß√£o de Testes

1) Instalar depend√™ncias de desenvolvimento

```bash
source .venv/bin/activate
pip install -r requirements-dev.txt
```

2) Rodar su√≠te de testes

```bash
pytest -q
```

3) Rodar testes com cobertura (comando oficial do projeto)

```bash
pytest --cov=src --cov-report=term-missing --cov-fail-under=80
```

Observa√ß√£o: mantenha este comando de cobertura sempre documentado no `README.md` para padronizar valida√ß√£o local e evid√™ncia t√©cnica da entrega.

## Logging

- Logging b√°sico centralizado em `src/utils.py` com `setup_logging()` e `get_logger()`.
- N√≠vel padr√£o: `INFO`. Para ajustar em runtime:
  - `LOG_LEVEL=DEBUG` (ou `INFO`, `WARNING`, `ERROR`)
  - Valores inv√°lidos de `LOG_LEVEL` fazem fallback para `INFO` (com warning em log).
- Sa√≠da padr√£o: `stdout`.
- Opcional: habilitar arquivo em `logs/app.log` com:
  - `LOG_TO_FILE=1`
- Idempot√™ncia: `setup_logging()` pode ser chamado m√∫ltiplas vezes sem duplicar handlers/logs.
- Privacidade operacional:
  - N√£o logar `RA`, listas de identificadores, payloads completos ou dados pessoais.
  - Logar apenas m√©tricas agregadas e contadores operacionais.

## Checklist do Projeto - Datathon Machine Learning Engineering

Este checklist foi elaborado considerando explicitamente as inconsist√™ncias reais do dataset fornecido (schemas distintos entre anos, colunas duplicadas, valores inv√°lidos, mudan√ßas sem√¢nticas de campos e interse√ß√£o parcial de estudantes entre per√≠odos). As etapas descritas adotam pr√°ticas de Data Engineering e MLOps para garantir robustez, reprodutibilidade e validade estat√≠stica do modelo em produ√ß√£o.

Status: `TODO` | `DOING` | `DONE` | `BLOCKED`

Progresso geral (barra visual):
`[üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú]`

`34 de 95 tarefas conclu√≠das (35.8%)`

| Fase | Progresso |
|---|---|
| Fase 1 - Entendimento do Problema e Target | 11/11 |
| Fase 2 - Organiza√ß√£o do Projeto e Ambiente | 7/7 |
| Fase 3 - Ingest√£o, Qualidade e Governan√ßa de Dados | 5/14 |
| Fase 4 - Pr√©-processamento e Engenharia de Features | 0/10 |
| Fase 5 - Pipeline, Treinamento e Avalia√ß√£o | 0/17 |
| Fase 6 - Artefatos, API e Deploy | 0/12 |
| Fase 7 - Testes, Monitoramento e Dashboard | 1/7 |
| Fase 8 - Documenta√ß√£o e Entrega Final | 10/15 |
| Total | 34/95 |

### Fase 1 - Entendimento do Problema e Target [11/11]
- [x] Compreender o objetivo de neg√≥cio: prever o risco de defasagem escolar (t+1)
- [x] Estudar o dicion√°rio de dados e as bases de 2022, 2023 e 2024
- [x] Padronizar a coluna de defasagem (`Defas` -> `Defasagem`)
- [x] Definir a formula√ß√£o do target bin√°rio
- [x] Definir m√©trica prim√°ria de sucesso (`Recall`) e m√©tricas secund√°rias (`PR-AUC`, `Precision`, `F1`, `ROC-AUC`) j√° na fase de desenho
- [x] Definir `y = 1` se `Defasagem_{t+1} < 0`
- [x] Definir `y = 0` caso contr√°rio
- [x] Definir a estrat√©gia de pares temporais
- [x] Definir treino: `X(2022) -> y(2023)`
- [x] Definir holdout final: `X(2023) -> y(2024)`
- [x] Garantir que `RA` seja usado apenas como ID, nunca como feature

### Fase 2 - Organiza√ß√£o do Projeto e Ambiente [7/7]
- [x] Configurar `.gitignore` inicial (ignorar `agents.md`, `dataset/` e `.DS_Store`)
- [x] Expandir `.gitignore` com padr√µes essenciais de Python/MLOps (cache, venv, cobertura, builds, logs e segredos locais)
- [x] Criar estrutura de diret√≥rios do projeto
- [x] Criar `requirements.txt` com depend√™ncias m√≠nimas
- [x] Fixar vers√µes das depend√™ncias para garantir reprodutibilidade do ambiente de execu√ß√£o
- [x] Definir `random_state` global para reprodutibilidade
- [x] Configurar logging b√°sico do projeto

### Fase 3 - Ingest√£o, Qualidade e Governan√ßa de Dados [5/14]
Camadas conceituais desta fase:
- Camada A - Pr√©-ingest√£o e Ingest√£o: contrato de dados, mapeamento de colunas equivalentes, tratamento de headers duplicados, normaliza√ß√£o de valores inv√°lidos, padroniza√ß√£o de datas e normaliza√ß√£o sem√¢ntica.
- Camada B - Governan√ßa e Valida√ß√£o Cont√≠nua: coorte temporal por `RA`, valida√ß√µes de shift, versionamento de dataset e privacidade operacional.

Nota de coorte temporal:
> A constru√ß√£o dos pares temporais considera apenas estudantes presentes em ambos os anos consecutivos (`t` e `t+1`), evitando vi√©s por evas√£o ou entrada tardia e garantindo consist√™ncia estat√≠stica na defini√ß√£o do target.

- [x] Implementar leitura do arquivo XLSX
- [x] Tratar diferen√ßas de colunas entre os anos
- [x] Padronizar nomes e tipos de dados
- [x] Criar fun√ß√£o de gera√ß√£o dos pares temporais (`t -> t+1`)
- [ ] Validar consist√™ncia dos dados (missing, tipos inv√°lidos)
- [ ] Definir um data contract por ano (nome, tipo e dom√≠nio esperado por coluna)
- [ ] Implementar valida√ß√£o autom√°tica do data contract (asserts de nome, tipo e dom√≠nio por coluna)
- [ ] Criar tabela de mapeamento entre colunas equivalentes (`Matem/Portug/Ingl√™s` <-> `Mat/Por/Ing`; `Defas` <-> `Defasagem`)
- [ ] Tratar headers duplicados na ingest√£o com regra determin√≠stica
- [ ] Normalizar valores inv√°lidos em campos num√©ricos (ex.: `#N/A`, `#DIV/0!`, `INCLUIR`)
- [ ] Padronizar datas de nascimento para formato √∫nico
- [ ] Normalizar categorias textuais entre anos (`Menina/Menino` <-> `Feminino/Masculino`; `Escola P√∫blica` <-> `P√∫blica`)
- [x] Definir regra formal de coorte temporal por `RA` (entradas, sa√≠das e interse√ß√µes por ano)
- [ ] Gerar e registrar estat√≠sticas de interse√ß√£o por `RA` entre anos (contagem absoluta e percentual)

### Fase 4 - Pr√©-processamento e Engenharia de Features [0/10]
- [ ] Separar features num√©ricas e categ√≥ricas
- [ ] Tratar valores ausentes (imputa√ß√£o)
- [ ] Codificar vari√°veis categ√≥ricas (`OneHotEncoder` ou similar)
- [ ] Escalonar vari√°veis num√©ricas (se necess√°rio)
- [ ] Garantir que o pr√©-processamento seja reutiliz√°vel na infer√™ncia
- [ ] Criar novas features relevantes (se aplic√°vel)
- [ ] Implementar checagem expl√≠cita de data leakage (lista negra de colunas futuras + asserts temporais)
- [ ] Remover colunas irrelevantes ou com leakage
- [ ] Garantir que nenhuma feature use informa√ß√£o futura
- [ ] Documentar as principais decis√µes de feature engineering

### Fase 5 - Pipeline, Treinamento e Avalia√ß√£o [0/17]
Nota de shift temporal:
> Antes do treinamento final, √© realizada uma an√°lise de shift temporal do target e das features, uma vez que a preval√™ncia da classe positiva varia significativamente entre os per√≠odos analisados (aprox. `61%` para `40%`).

- [ ] Criar `ColumnTransformer` para pr√©-processamento
- [ ] Encapsular tudo em uma `Pipeline` do scikit-learn
- [ ] Garantir consist√™ncia treino vs infer√™ncia
- [ ] Validar que a pipeline aceita dados crus da API
- [ ] Treinar modelo baseline (`Logistic Regression`)
- [ ] Treinar modelo n√£o-linear (ex.: `HistGradientBoosting`)
- [ ] Usar apenas dados de treino (`2022 -> 2023`)
- [ ] (Opcional) Valida√ß√£o interna (CV estratificada)
- [ ] Definir estrat√©gia expl√≠cita para desbalanceamento de classes (`class_weight`, ajuste de threshold ou decis√£o justificada de n√£o tratar)
- [ ] Comparar modelos com foco em Recall e PR-AUC
- [ ] Avaliar desempenho no holdout temporal (`2023 -> 2024`)
- [ ] Calcular m√©tricas: Recall, Precision, F1-score, ROC-AUC, PR-AUC
- [ ] Gerar matriz de confus√£o
- [ ] Definir threshold operacional focado em Recall
- [ ] Definir crit√©rio objetivo formal de sele√ß√£o do modelo final (ex.: maior Recall com PR-AUC acima de limiar m√≠nimo)
- [ ] Justificar escolha do modelo final
- [ ] Incluir valida√ß√£o de shift temporal do target e das features antes do treinamento final

### Fase 6 - Artefatos, API e Deploy [0/12]
- [ ] Salvar pipeline completa em `model.joblib`
- [ ] Criar `metadata.json` com modelo, m√©tricas, threshold, features esperadas, data do treino e vers√µes das bibliotecas
- [ ] Salvar dados de refer√™ncia para monitoramento de drift
- [ ] Versionar dataset de treino/valida√ß√£o (`hash/checksum` + vers√£o usada no experimento)
- [ ] Definir schema formal de sa√≠da do modelo/API (probabilidade, classe prevista, threshold aplicado e vers√£o do modelo)
- [ ] Criar aplica√ß√£o FastAPI
- [ ] Implementar endpoint `POST /predict`
- [ ] Implementar `GET /health` e `GET /version`
- [ ] Validar entradas com Pydantic
- [ ] Garantir carregamento do modelo salvo
- [ ] Criar Dockerfile enxuto baseado em `python:slim`
- [ ] Documentar comandos de build e run no README

### Fase 7 - Testes, Monitoramento e Dashboard [1/7]
- [ ] Criar testes unit√°rios e de integra√ß√£o com pytest
- [x] Garantir cobertura m√≠nima de 80% com `pytest-cov`
- [ ] Implementar teste de n√£o-regress√£o do modelo com limiares m√≠nimos de m√©tricas (ex.: Recall e/ou PR-AUC)
- [ ] Configurar logging estruturado
- [ ] Aplicar pol√≠tica de privacidade operacional (n√£o logar identificadores sens√≠veis como `RA` em API e monitoramento)
- [ ] Implementar relat√≥rio de drift com Evidently
- [ ] Criar aplica√ß√£o Streamlit para visualiza√ß√£o do relat√≥rio de drift

### Fase 8 - Documenta√ß√£o e Entrega Final [10/15]
- [x] Documentar vis√£o geral do problema e objetivo
- [ ] Documentar stack tecnol√≥gica
- [x] Documentar estrutura do projeto
- [ ] Documentar etapas do pipeline de Machine Learning
- [ ] Documentar limita√ß√µes conhecidas do modelo e riscos assumidos
- [ ] Documentar exemplos de chamadas √† API
- [x] Documentar setup de ambiente local com `.venv` e instala√ß√£o de depend√™ncias
- [ ] Publicar c√≥digo organizado no GitHub
- [ ] Disponibilizar API acess√≠vel localmente
- [ ] Gravar v√≠deo gerencial (<= 5 minutos) explicando a solu√ß√£o
- [x] Criar `agents.md` com conven√ß√µes operacionais para agentes LLM
- [x] Adicionar barra de progresso geral visual (`[üü©‚¨ú...]`) no checklist
- [x] Atualizar `agents.md` com regra expl√≠cita de manuten√ß√£o da barra visual e da contagem geral
- [x] Incorporar recomenda√ß√µes da revis√£o t√©cnica do checklist (gaps de maturidade por fase)
- [x] Refinar reda√ß√£o do objetivo para "apresentar defasagem no t+1" (evita ambiguidade de transi√ß√£o vs estado)
- [x] Refinar vis√£o geral com v√≠nculo expl√≠cito a `Defas/Defasagem` e regra de coorte por `RA`
- [x] Adicionar men√ß√£o expl√≠cita de n√£o-causalidade do modelo na se√ß√£o de contexto de uso

<details>
<summary>Notas de uso do checklist</summary>

- Atualize os contadores de progresso de cada fase ao concluir tarefas.
- Atualize a barra visual de progresso geral (`[üü©‚¨ú...]`) com base na porcentagem conclu√≠da.
- Marque uma tarefa como `DOING` no texto do item quando estiver em andamento.
- Promova para `DONE` apenas ap√≥s evid√™ncia (teste, artefato, log ou documenta√ß√£o).
- Use `BLOCKED` quando depender de decis√£o, dado externo ou ajuste de escopo.

</details>
